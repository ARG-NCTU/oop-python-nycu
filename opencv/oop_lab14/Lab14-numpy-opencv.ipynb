{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab2c95a",
   "metadata": {},
   "source": [
    "# Lab14: NumPy + OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3037078",
   "metadata": {},
   "source": [
    "## Lab Goals\n",
    "\n",
    "**Demo1**: Change crying emoji into smiley emoji\n",
    "\n",
    "**Demo2**: Do histogram equalization on provided image\n",
    "\n",
    "If you are not using docker containers or devcontainers\n",
    "```bash\n",
    "    pip install numpy opencv-python matplotlib  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_img(img, title=\"Image\"):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a176bfb",
   "metadata": {},
   "source": [
    "## TA demo\n",
    "\n",
    "real-time line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    eroded = cv2.erode(thresh, None, iterations=2)\n",
    "    dilated = cv2.dilate(eroded, None, iterations=2)\n",
    "    edges = cv2.Canny(dilated, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def apply_roi_mask(edges, width, height):\n",
    "    vertices = np.array([[\n",
    "        (0, height), (width//20, 2*height//6),\n",
    "        (19*width//20, 2*height//6), (width, height)\n",
    "    ]], dtype=np.int32)\n",
    "\n",
    "    mask = np.zeros_like(edges)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    return cv2.bitwise_and(edges, mask)\n",
    "\n",
    "def classify_lines(lines, width):\n",
    "    left_lines, right_lines = [], []\n",
    "    middle_x = width / 2\n",
    "\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if x1 == x2:\n",
    "            continue\n",
    "        slope = (y2-y1) / (x2 - x1)\n",
    "        if 0.35 < slope < 0.85 and x1 > middle_x/2:\n",
    "            right_lines.append(line)\n",
    "        elif -0.85 < slope < -0.35 and x1 < 3*width/4:\n",
    "            left_lines.append(line)\n",
    "    return left_lines, right_lines\n",
    "\n",
    "def calculate_triangle_area(vertices):\n",
    "    x1, y1 = vertices[0]\n",
    "    x2, y2 = vertices[1]\n",
    "    x3, y3 = vertices[2]\n",
    "    area = abs(x1*(y2-y3) + x2*(y3-y1) + x3*(y1-y2)) / 2.0\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = preprocess_frame(frame)\n",
    "    masked = apply_roi_mask(edges, width, height)\n",
    "\n",
    "    edges = preprocess_frame(frame)\n",
    "    masked = apply_roi_mask(edges, width, height)\n",
    "    lines = cv2.HoughLinesP(masked, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "    if lines is not None:\n",
    "        left_lines, right_lines = classify_lines(lines, width)\n",
    "\n",
    "        for line in left_lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(overlay, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        for line in right_lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(overlay, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    # Triangle detection region: upper 2/3\n",
    "    mask_tri = np.zeros_like(edges)\n",
    "    roi_tri = np.array([[(0, 0), (width, 0), (width, 2*height//3), (0, 2*height//3)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask_tri, roi_tri, 255)\n",
    "    edges_tri = cv2.bitwise_and(edges, mask_tri)\n",
    "\n",
    "    contours, _ = cv2.findContours(edges_tri, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(approx) == 3:\n",
    "            area = calculate_triangle_area(approx[:, 0, :])\n",
    "            if area > 15000:\n",
    "                centroid = np.mean(approx, axis=0)\n",
    "                distances = np.linalg.norm(approx[:, 0, :] - centroid, axis=1)\n",
    "                tip = approx[np.argmax(distances)][0]\n",
    "                if tip[0] > centroid[0][0]:\n",
    "                    direction = 'Right'\n",
    "                    color = (255, 255, 0)   # Blue for right\n",
    "                else:\n",
    "                    direction = 'Left'\n",
    "                    color = (0, 0, 255)   # Red for left\n",
    "\n",
    "                cv2.drawContours(overlay, [approx], -1, color, 3)\n",
    "                cv2.putText(overlay, f\"Triangle: {direction}\", (20, 50),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                break  # Only detect one triangle\n",
    "    # Display the frame using matplotlib\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Frame\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886f1a6",
   "metadata": {},
   "source": [
    "# Demo1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555a6ae",
   "metadata": {},
   "source": [
    "### Step 0. Load Image\n",
    "\n",
    "replace ```'your_image.jpg'``  with the path to the sad-man image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43995a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sad_man.jpg')\n",
    "if img is None:\n",
    "    raise ValueError(\"Image not found. Please check the path.\")\n",
    "show_img(img, \"Original Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98923e73",
   "metadata": {},
   "source": [
    "### Step 1. Color tracker - yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0427b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code below ### find contours for yellow region\n",
    "\n",
    "contours, _ =\n",
    "### your code above ###\n",
    "img_contours = img.copy()\n",
    "cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 2)\n",
    "show_img(img_contours, \"Color Contours: Yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106d085",
   "metadata": {},
   "source": [
    "### Step 2. Bound the roi with a box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46620b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code below ###\n",
    "\n",
    "\n",
    "### your code above ###\n",
    "show_img(img_blobs, f\"ROI bounding box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84929e3",
   "metadata": {},
   "source": [
    "### Step 3. Replace crying face with smiley face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code below ### overlay the ROI with smiley face emoji\n",
    "\n",
    "### your code above ###\n",
    "show_img(img, \"smiley man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5cc94d",
   "metadata": {},
   "source": [
    "# Demo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"cbum.jpg\")\n",
    "### your code below ###\n",
    "#### histogram equalized ####\n",
    "\n",
    "\n",
    "#############################\n",
    "#### CLAHE processing ####\n",
    "\n",
    "\n",
    "##########################\n",
    "### your code above ###\n",
    "\n",
    "# Plot\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "eq_rgb = cv2.cvtColor(equalized, cv2.COLOR_GRAY2RGB)\n",
    "clahe_rgb = cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(15, 5))\n",
    "titles = [\"Original\", \"Histogram Equalized\", \"CLAHE Enhanced\"]\n",
    "images = [img_rgb, eq_rgb, clahe_rgb]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
